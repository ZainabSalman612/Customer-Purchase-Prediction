{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219fa0ae",
   "metadata": {},
   "source": [
    "# Customer Purchase Prediction\n",
    "\n",
    "This notebook demonstrates a machine learning project to predict whether a customer will purchase a product based on features like time on site, pages viewed, device, and referral source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e251f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dad44d",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "We will generate synthetic data for demonstration purposes. The features are:\n",
    "- time_on_site: continuous, minutes spent on site\n",
    "- pages_viewed: integer, number of pages viewed\n",
    "- device: categorical, 'mobile', 'desktop', 'tablet'\n",
    "- referral_source: categorical, 'google', 'facebook', 'direct', 'email'\n",
    "\n",
    "Target: purchase (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae5493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_on_site  pages_viewed   device referral_source  purchase\n",
      "0      4.238813             1  desktop        facebook         0\n",
      "1      0.237570             3  desktop          direct         1\n",
      "2      4.890292             4  desktop          direct         0\n",
      "3      4.918809             4   tablet          google         0\n",
      "4     11.091256             4  desktop           email         1\n",
      "       time_on_site  pages_viewed     purchase\n",
      "count   1000.000000   1000.000000  1000.000000\n",
      "mean       5.177034      3.975000     0.414000\n",
      "std        4.963842      1.741093     0.492795\n",
      "min        0.027066      1.000000     0.000000\n",
      "25%        1.586782      3.000000     0.000000\n",
      "50%        3.721620      4.000000     0.000000\n",
      "75%        7.368239      5.000000     1.000000\n",
      "max       41.298671     12.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "n_samples = 1000\n",
    "\n",
    "# Features\n",
    "time_on_site = np.random.exponential(5, n_samples)  # exponential distribution\n",
    "pages_viewed = np.random.poisson(3, n_samples) + 1  # poisson +1 to avoid 0\n",
    "device = np.random.choice(['mobile', 'desktop', 'tablet'], n_samples)\n",
    "referral_source = np.random.choice(['google', 'facebook', 'direct', 'email'], n_samples)\n",
    "\n",
    "# Target: purchase probability depends on features\n",
    "purchase_prob = 0.1 + 0.01 * time_on_site + 0.05 * pages_viewed\n",
    "purchase_prob += np.where(device == 'desktop', 0.1, 0)\n",
    "purchase_prob += np.where(referral_source == 'google', 0.05, 0)\n",
    "purchase_prob = np.clip(purchase_prob, 0, 1)\n",
    "purchase = np.random.binomial(1, purchase_prob)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'time_on_site': time_on_site,\n",
    "    'pages_viewed': pages_viewed,\n",
    "    'device': device,\n",
    "    'referral_source': referral_source,\n",
    "    'purchase': purchase\n",
    "})\n",
    "\n",
    "print(data.head())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01915ecd",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Handle categorical variables using label encoding and scale numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d4245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_on_site  pages_viewed  device_encoded  referral_encoded\n",
      "0     -0.189106     -1.709551               0                 2\n",
      "1     -0.995587     -0.560273               0                 0\n",
      "2     -0.057795      0.014366               0                 0\n",
      "3     -0.052047      0.014366               2                 3\n",
      "4      1.192057      0.014366               0                 1\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# Encode categorical variables\n",
    "le_device = LabelEncoder()\n",
    "le_referral = LabelEncoder()\n",
    "\n",
    "data['device_encoded'] = le_device.fit_transform(data['device'])\n",
    "data['referral_encoded'] = le_referral.fit_transform(data['referral_source'])\n",
    "\n",
    "# Features and target\n",
    "X = data[['time_on_site', 'pages_viewed', 'device_encoded', 'referral_encoded']]\n",
    "y = data['purchase']\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['time_on_site', 'pages_viewed']] = scaler.fit_transform(X[['time_on_site', 'pages_viewed']])\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfbc812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (800, 4), Test shape: (200, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3961d7",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Train Logistic Regression and Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8c2bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained.\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Models trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c16d02b",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate models on test data using accuracy and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae3a96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.64, Precision: 0.60\n",
      "Random Forest - Accuracy: 0.58, Precision: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "prec_log = precision_score(y_test, y_pred_log)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {acc_log:.2f}, Precision: {prec_log:.2f}\")\n",
    "print(f\"Random Forest - Accuracy: {acc_rf:.2f}, Precision: {prec_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04b0d0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the basics of a customer purchase prediction project, including data generation, preprocessing, model training with Logistic Regression and Random Forest, and evaluation with accuracy and precision metrics. In a real project, you would use actual data and perform hyperparameter tuning, cross-validation, and more advanced evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
